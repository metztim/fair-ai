# AI Bubble LinkedIn Post - Draft v2

Everyone's calling this an AI bubble.

What if the scarier truth is that it's not?

The analysts point to the numbers: $560 billion invested, $35 billion in revenue. OpenAI valued at $500 billion with $8 billion in revenue. Nvidia's $100 billion circular financing deals.

The math doesn't work. It's obviously a bubble.

Except.

I've been working with Claude Code all day, every day, for months now. And from what I'm seeing—just as a regular person with publicly available models—I could automate at least 25% of work at most companies I've looked at.

Not the creative work. That's still complicated.

The boring stuff.

Admin, finance, legal processing, project management, documentation, approvals. With current models, that stuff can be automated 80-90%.

And this is what's publicly released.

Here's what makes me uncomfortable: when analysts call this a bubble, they're measuring current revenue against current valuations. But what if these valuations aren't pricing current revenue? What if they're pricing near-term labor displacement?

How much do we spend on knowledge worker salaries globally? Trillions.

If the AI labs can see—with their internal models that are 12-24 months ahead of what we have access to—that they can start replacing significant chunks of knowledge work over the next few years, then $500 billion valuations aren't hype. They're rational bets on capturing a massive value transfer. From salaries to compute.

That's not a bubble. That's just math.

But here's the thing: most analysts don't see this because they don't actually use these models. Benedict Evans admitted on a podcast he doesn't really use AI for anything. (He's a professional technology analyst.) If you think the technology is disappointing based on headlines and other people's opinions, it's easy to call it a bubble.

But if you've actually pushed these models hard enough to see what they can do right now, the valuations start to look different.

The Upwork survey shows the disconnect: 96% of executives expected AI to boost productivity, but 77% of employees using it say it added to their workload. That's not the technology failing. That's most people being 12-24 months behind on knowing how to use it.

Meanwhile, the labs are 12-24 months ahead with internal models. GPT-6. Sonnet-6. Whatever's coming next.

They can see what we can't.

Marc Andreessen has a test for bubbles: Does the technology work? Yes. Are customers paying? Yes. Then it's probably on track.

The bubble narrative is comforting. It says normal comes back eventually. Reality reasserts itself. Things settle down.

But what if normal doesn't come back?

I'm 50-50 on whether new work will emerge to replace what gets automated. Maybe 60-40 against. But either way, it won't be the same jobs for the same people.

Which means we should probably hope the analysts are right about the bubble.

Because if they're wrong—if these valuations are rational—we're looking at something much bigger than a financial correction.

Have you pushed the latest models hard enough to see what they can do?

---

**DRAFT NOTES:**
- Uses research from Logseq (Upwork survey, Benedict Evans, Andreessen/Horowitz test)
- Cites recent web research (Ed Zitron Q3 2026, Deutsche Bank, $560B/$35B ratio)
- Personal experience anchored throughout
- Structure: provocative hook → personal evidence → the gap → uncomfortable math → historical context → ending question
- Needs Tim's review for voice authenticity and any deletions
